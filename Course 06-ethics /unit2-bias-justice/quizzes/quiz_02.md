# Quiz 02: Bias, Justice, and Discrimination | Ø§Ø®ØªØ¨Ø§Ø± 02: Ø§Ù„ØªØ­ÙŠØ² ÙˆØ§Ù„Ø¹Ø¯Ø§Ù„Ø© ÙˆØ§Ù„ØªÙ…ÙŠÙŠØ²

## Instructions | Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª
- **Time Limit**: 30 minutes
- **Total Points**: 50 points
- **Format**: Multiple choice, short answer
- **Allowed Resources**: None (closed book)

---

## Part 1: Types of Bias (15 points)

### Question 1 (5 points)
What is algorithmic bias?
- A) Model errors
- B) Systematic unfairness in AI systems
- C) Data quality issues
- D) Computational limitations

**Answer:** B

---

### Question 2 (5 points)
What is data bias?
- A) Missing values
- B) Systematic errors in training data
- C) Small datasets
- D) Data format issues

**Answer:** B

---

### Question 3 (5 points)
What is intersectional bias?
- A) Single group bias
- B) Bias affecting multiple overlapping groups
- C) No bias
- D) Random bias

**Answer:** B

---

## Part 2: Fairness Metrics (15 points)

### Question 4 (5 points)
What does demographic parity measure?
- A) Accuracy
- B) Equal positive prediction rates across groups
- C) Model speed
- D) Data size

**Answer:** B

---

### Question 5 (5 points)
What is equalized odds?
- A) Equal accuracy
- B) Equal true positive and false positive rates across groups
- C) Equal predictions
- D) Equal data

**Answer:** B

---

### Question 6 (5 points)
What is calibration in fairness?
- A) Model tuning
- B) Equal prediction confidence across groups
- C) Data cleaning
- D) Feature selection

**Answer:** B

---

## Part 3: Bias Detection (10 points)

### Question 7 (5 points)
What tools can be used to detect bias?
- A) Only manual inspection
- B) Fairlearn, aif360, statistical tests
- C) Only visualization
- D) Only accuracy metrics

**Answer:** B

---

### Question 8 (5 points)
What should be analyzed to detect bias?
- A) Only model accuracy
- B) Dataset composition, model outputs, protected attributes
- C) Only data size
- D) Only model speed

**Answer:** B

---

## Part 4: Bias Mitigation (10 points)

### Question 9 (5 points)
What is pre-processing bias mitigation?
- A) Fixing data after training
- B) Addressing bias in training data before model training
- C) Only post-processing
- D) Ignoring bias

**Answer:** B

---

### Question 10 (5 points)
What is a trade-off in fairness?
- A) No trade-offs exist
- B) Different fairness definitions may conflict
- C) Always use same definition
- D) Fairness is always achievable

**Answer:** B

---

## Answer Key | Ù…ÙØªØ§Ø­ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª

1. B - Systematic unfairness in AI systems
2. B - Systematic errors in training data
3. B - Bias affecting multiple overlapping groups
4. B - Equal positive prediction rates across groups
5. B - Equal true positive and false positive rates across groups
6. B - Equal prediction confidence across groups
7. B - Fairlearn, aif360, statistical tests
8. B - Dataset composition, model outputs, protected attributes
9. B - Addressing bias in training data before model training
10. B - Different fairness definitions may conflict

---

**Good luck!** ğŸ€

